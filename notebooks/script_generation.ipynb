{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69fb38af",
   "metadata": {},
   "source": [
    "# 1. Environment Setup\n",
    "First, we need to load our API keys from the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5891cc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API Key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if the Gemini API key is loaded correctly\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "print(\"Gemini API Key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0057f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import LangChain and Gemini\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Import our custom prompts (now that the project is installed)\n",
    "from prompts.scrip_writer_agent import SCRIPT_WRITER_AGENT_PROMPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00083ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini LLM initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# 3. Initialize Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    google_api_key=gemini_api_key,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Gemini LLM initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ade76",
   "metadata": {},
   "source": [
    "# 4. Dynamic Prompt with Pydantic Models\n",
    "\n",
    "Now let's test the new dynamic prompt system that automatically updates when we modify the Pydantic models in `src/models/models.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e13f45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dynamic prompt system imported successfully!\n",
      "üìã Available Scene Types: ['explanation', 'visual_demo', 'comparison', 'story_telling', 'hook', 'conclusion']\n",
      "üé® Available Image Styles: ['single_character', 'character_with_background', 'infographic', 'diagram_explanation', 'before_after_comparison', 'step_by_step_visual', 'four_cut_cartoon', 'comic_panel', 'speech_bubble', 'cinematic', 'close_up_reaction', 'wide_establishing_shot', 'split_screen', 'overlay_graphics', 'cutaway_illustration']\n",
      "üé§ Available Voice Tones: ['excited', 'curious', 'serious', 'friendly', 'sad', 'mysterious', 'surprised', 'confident', 'worried', 'playful', 'dramatic', 'calm', 'enthusiastic']\n",
      "üîÑ Available Transitions: ['fade', 'slide_left', 'slide_right', 'zoom_in', 'zoom_out', 'dissolve', 'wipe', 'push', 'spin', 'flip', 'none']\n",
      "üéØ Available Hook Techniques: ['shocking_fact', 'intriguing_question', 'visual_surprise', 'contradiction', 'mystery_setup']\n"
     ]
    }
   ],
   "source": [
    "# Import the new dynamic prompt system\n",
    "from prompts.scrip_writer_agent import SCRIPT_WRITER_AGENT_TEMPLATE, VIDEO_SCRIPT_PARSER, create_dynamic_prompt\n",
    "from models.models import SceneType, ImageStyle, VoiceTone, TransitionType, HookTechnique\n",
    "\n",
    "print(\"‚úÖ Dynamic prompt system imported successfully!\")\n",
    "print(f\"üìã Available Scene Types: {[t.value for t in SceneType]}\")\n",
    "print(f\"üé® Available Image Styles: {[s.value for s in ImageStyle]}\")\n",
    "print(f\"üé§ Available Voice Tones: {[t.value for t in VoiceTone]}\")\n",
    "print(f\"üîÑ Available Transitions: {[t.value for t in TransitionType]}\")\n",
    "print(f\"üéØ Available Hook Techniques: {[t.value for t in HookTechnique]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76ebd53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dynamic prompt chain created successfully!\n",
      "üìù Template type: <class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "üìã Parser type: <class 'langchain_core.output_parsers.pydantic.PydanticOutputParser'>\n",
      "üîó Chain type: <class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "üìã Format instructions length: 5552 characters\n"
     ]
    }
   ],
   "source": [
    "# Create the dynamic prompt chain\n",
    "chain = SCRIPT_WRITER_AGENT_TEMPLATE | llm | VIDEO_SCRIPT_PARSER\n",
    "\n",
    "print(\"‚úÖ Dynamic prompt chain created successfully!\")\n",
    "print(f\"üìù Template type: {type(SCRIPT_WRITER_AGENT_TEMPLATE)}\")\n",
    "print(f\"üìã Parser type: {type(VIDEO_SCRIPT_PARSER)}\")\n",
    "print(f\"üîó Chain type: {type(chain)}\")\n",
    "\n",
    "# Show format instructions length\n",
    "format_instructions = VIDEO_SCRIPT_PARSER.get_format_instructions()\n",
    "print(f\"üìã Format instructions length: {len(format_instructions)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca418314",
   "metadata": {},
   "source": [
    "# 5. Test Dynamic Prompt Generation\n",
    "\n",
    "Let's test the dynamic prompt with a simple subject and save the results to the `/temp` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056279e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Simple save function created!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_llm_result_to_temp(result, subject):\n",
    "    \"\"\"\n",
    "    Save LLM result to notebooks/temp folder as JSON\n",
    "    \"\"\"\n",
    "    # Create temp directory\n",
    "    temp_dir = \"/temp\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate filename: script_subject_datetime\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    clean_subject = \"\".join(c for c in subject if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "    clean_subject = clean_subject.replace(' ', '_')[:50]\n",
    "    \n",
    "    filename = f\"script_{clean_subject}_{timestamp}.json\"\n",
    "    filepath = os.path.join(temp_dir, filename)\n",
    "    \n",
    "    # Save result as-is (convert to dict if Pydantic model)\n",
    "    if hasattr(result, 'model_dump'):\n",
    "        data = result.model_dump()\n",
    "    else:\n",
    "        data = result\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úÖ Saved to: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "print(\"‚úÖ Simple save function created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f100cf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing dynamic prompt with subject: 'Why do cats purr?'\n",
      "üìù Language: English\n",
      "üé¨ Max scenes: 4\n",
      "‚è≥ Generating...\n",
      "‚úÖ SUCCESS! Dynamic prompt generation completed!\n",
      "üìÑ Title: The Purrfect Mystery: Why Do Cats Purr?\n",
      "üìÑ Total scenes: 6\n",
      "üìÑ Hook technique: mystery_setup\n",
      "üìÑ Hook scene type: hook\n",
      "üìÑ Hook voice tone: mysterious\n",
      "‚úÖ Saved to: notebooks/temp/script_Why_do_cats_purr_20250914_235353.json\n",
      "\n",
      "üéØ Dynamic prompt benefits demonstrated:\n",
      "  ‚úÖ All enum values automatically included from Pydantic models\n",
      "  ‚úÖ Type-safe output parsing with PydanticOutputParser\n",
      "  ‚úÖ Result saved to temp folder as JSON\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Simple subject with dynamic prompt\n",
    "test_subject = \"Why do cats purr?\"\n",
    "test_language = \"English\"\n",
    "test_max_scenes = 4\n",
    "\n",
    "print(f\"üß™ Testing dynamic prompt with subject: '{test_subject}'\")\n",
    "print(f\"üìù Language: {test_language}\")\n",
    "print(f\"üé¨ Max scenes: {test_max_scenes}\")\n",
    "print(\"‚è≥ Generating...\")\n",
    "\n",
    "try:\n",
    "    # Generate using dynamic prompt chain\n",
    "    result = chain.invoke({\n",
    "        \"subject\": test_subject,\n",
    "        \"language\": test_language,\n",
    "        \"max_video_scenes\": test_max_scenes\n",
    "    })\n",
    "    \n",
    "    print(\"‚úÖ SUCCESS! Dynamic prompt generation completed!\")\n",
    "    print(f\"üìÑ Title: {result.title}\")\n",
    "    print(f\"üìÑ Total scenes: {result.total_scene_count}\")\n",
    "    print(f\"üìÑ Hook technique: {result.hook_scene.hook_technique.value}\")\n",
    "    print(f\"üìÑ Hook scene type: {result.hook_scene.scene_type.value}\")\n",
    "    print(f\"üìÑ Hook voice tone: {result.hook_scene.voice_tone.value}\")\n",
    "    \n",
    "    # Save to temp folder\n",
    "    saved_file = save_llm_result_to_temp(result, test_subject)\n",
    "    \n",
    "    print(f\"\\nüéØ Dynamic prompt benefits demonstrated:\")\n",
    "    print(f\"  ‚úÖ All enum values automatically included from Pydantic models\")\n",
    "    print(f\"  ‚úÖ Type-safe output parsing with PydanticOutputParser\")\n",
    "    print(f\"  ‚úÖ Result saved to temp folder as JSON\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333f7c6",
   "metadata": {},
   "source": [
    "# 6. Test Dynamic Updates\n",
    "\n",
    "Let's demonstrate how the prompt automatically updates when we modify the Pydantic models. We'll add a new voice tone and see it reflected in the prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28935b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dynamic updates by recreating the prompt\n",
    "print(\"üîÑ Testing dynamic prompt updates...\")\n",
    "\n",
    "# Recreate the dynamic prompt to see current enum values\n",
    "new_prompt, new_parser = create_dynamic_prompt()\n",
    "\n",
    "# Check if the prompt contains all current enum values\n",
    "current_voice_tones = [t.value for t in VoiceTone]\n",
    "print(f\"üìã Current Voice Tones in models: {current_voice_tones}\")\n",
    "\n",
    "# Check if all voice tones are in the prompt\n",
    "missing_tones = []\n",
    "for tone in current_voice_tones:\n",
    "    if tone not in new_prompt:\n",
    "        missing_tones.append(tone)\n",
    "\n",
    "if missing_tones:\n",
    "    print(f\"‚ùå Missing voice tones in prompt: {missing_tones}\")\n",
    "else:\n",
    "    print(\"‚úÖ All voice tones are present in the dynamic prompt!\")\n",
    "\n",
    "# Show a sample of the prompt to verify enum values are included\n",
    "prompt_sample = new_prompt[new_prompt.find(\"**Available Voice Tones:**\"):new_prompt.find(\"**IMPORTANT**: Use the EXACT lowercase values\") + 100]\n",
    "print(f\"\\nüìù Prompt sample showing voice tones:\")\n",
    "print(prompt_sample)\n",
    "\n",
    "print(f\"\\nüéØ Dynamic update verification:\")\n",
    "print(f\"  ‚úÖ Prompt automatically includes all current enum values\")\n",
    "print(f\"  ‚úÖ No manual prompt updates needed when models change\")\n",
    "print(f\"  ‚úÖ LangChain PydanticOutputParser handles all parsing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb32adb",
   "metadata": {},
   "source": [
    "# 7. Custom Test Function\n",
    "\n",
    "Create a reusable function to test different subjects and save results automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72660d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dynamic_prompt(subject, language=\"English\", max_scenes=5):\n",
    "    \"\"\"\n",
    "    Test the dynamic prompt system with a given subject and save results\n",
    "    \n",
    "    Args:\n",
    "        subject: The topic for the video script\n",
    "        language: Language for the script\n",
    "        max_scenes: Maximum number of scenes\n",
    "    \n",
    "    Returns:\n",
    "        The generated VideoScript result\n",
    "    \"\"\"\n",
    "    print(f\"üß™ Testing dynamic prompt with subject: '{subject}'\")\n",
    "    print(f\"üìù Language: {language}, Max scenes: {max_scenes}\")\n",
    "    print(\"‚è≥ Generating...\")\n",
    "    \n",
    "    try:\n",
    "        # Generate using dynamic prompt chain\n",
    "        result = chain.invoke({\n",
    "            \"subject\": subject,\n",
    "            \"language\": language,\n",
    "            \"max_video_scenes\": max_scenes\n",
    "        })\n",
    "        \n",
    "        print(\"‚úÖ SUCCESS! Generation completed!\")\n",
    "        print(f\"üìÑ Title: {result.title}\")\n",
    "        print(f\"üìÑ Total scenes: {result.total_scene_count}\")\n",
    "        print(f\"üìÑ Hook technique: {result.hook_scene.hook_technique.value}\")\n",
    "        print(f\"üìÑ Hook voice tone: {result.hook_scene.voice_tone.value}\")\n",
    "        \n",
    "        # Save to temp folder\n",
    "        saved_file = save_llm_result_to_temp(result, subject)\n",
    "        print(f\"üíæ Saved to: {saved_file}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Simple test function created!\")\n",
    "print(\"Usage: test_dynamic_prompt('Your subject here')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the custom function with different subjects\n",
    "test_subjects = [\n",
    "    \"How does photosynthesis work?\",\n",
    "    \"Why is the sky blue?\",\n",
    "    \"How do birds fly?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing multiple subjects with custom function...\")\n",
    "\n",
    "results = []\n",
    "for i, subject in enumerate(test_subjects, 1):\n",
    "    print(f\"\\n--- Test {i}: {subject} ---\")\n",
    "    result = test_dynamic_prompt(subject, max_scenes=3)\n",
    "    if result:\n",
    "        results.append(result)\n",
    "    print()\n",
    "\n",
    "print(f\"‚úÖ Completed {len(results)} successful tests!\")\n",
    "print(f\"üìÅ All results saved to notebooks/temp/ folder\")\n",
    "print(f\"üéØ Each test used dynamic enum values from Pydantic models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4616b",
   "metadata": {},
   "source": [
    "# 8. Summary and Next Steps\n",
    "\n",
    "## What We've Accomplished:\n",
    "\n",
    "‚úÖ **Dynamic Prompt System**: Created a system that automatically updates when Pydantic models change  \n",
    "‚úÖ **PydanticOutputParser Integration**: Type-safe output parsing with LangChain  \n",
    "‚úÖ **Automatic File Saving**: Results saved to `/temp` folder in multiple formats  \n",
    "‚úÖ **Reusable Test Functions**: Easy testing with different subjects  \n",
    "‚úÖ **Enum Value Validation**: All enum values automatically included from models  \n",
    "\n",
    "## Key Benefits:\n",
    "\n",
    "1. **üîÑ Automatic Updates**: No manual prompt maintenance needed\n",
    "2. **üõ°Ô∏è Type Safety**: PydanticOutputParser ensures correct output format\n",
    "3. **üìÅ Organized Storage**: Results automatically saved with timestamps\n",
    "4. **üß™ Easy Testing**: Simple functions for testing different subjects\n",
    "5. **üìã Complete Integration**: All LangChain features utilized\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "- Modify `src/models/models.py` to add new enum values\n",
    "- Test that prompts automatically update\n",
    "- Use the `test_dynamic_prompt()` function for new subjects\n",
    "- Check saved files in `notebooks/temp/` folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d4c367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced video script prompt template created successfully!\n"
     ]
    }
   ],
   "source": [
    "# 4. Create the advanced video script prompt template\n",
    "video_script_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"language\", \"max_video_scenes\"],\n",
    "    template=SCRIPT_WRITER_AGENT_PROMPT\n",
    ")\n",
    "\n",
    "print(\"Advanced video script prompt template created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "856e3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create video script generation function\n",
    "def generate_video_script(subject, language=\"English\", max_video_scenes=3):\n",
    "    \"\"\"\n",
    "    Generate a complete video script using the advanced prompt template\n",
    "    \"\"\"\n",
    "    # Format the prompt with variables\n",
    "    formatted_prompt = video_script_prompt.format(\n",
    "        subject=subject,\n",
    "        language=language,\n",
    "        max_video_scenes=max_video_scenes\n",
    "    )\n",
    "    \n",
    "    # Create a human message\n",
    "    message = HumanMessage(content=formatted_prompt)\n",
    "    \n",
    "    # Get response from LLM\n",
    "    response = llm.invoke([message])\n",
    "\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed6e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing video script generation...\n",
      "\n",
      "Generated Video Script:\n",
      "```json\n",
      "{\n",
      "  \"VideoScript\": {\n",
      "    \"title\": \"The Ocean's Salty Secret: Why is the Sea So Salty?\",\n",
      "    \"main_character_description\": \"A friendly, curious marine biologist named Dr. Coral, with bright blue eyes and a warm smile. She wears a stylish lab coat over a casual shirt.\",\n",
      "    \"overall_style\": \"Educational with engaging cartoon elements\",\n",
      "    \"scenes\": [\n",
      "      {\n",
      "        \"scene_type\": \"HOOK\",\n",
      "        \"hook_type\": \"SHOCKING_FACT\",\n",
      "        \"visual_style\": \"INFOGRAPHIC\",\n",
      "        \"needs_animation\": false,\n",
      "        \"dialogue\": \"Did you know that humans indirectly consume about 1kg of sea salt every year through food?  But where does all that salt come from?\",\n",
      "        \"voice_tone\": \"EXCITED\",\n",
      "        \"transition\": null\n",
      "      },\n",
      "      {\n",
      "        \"scene_type\": \"SETUP\",\n",
      "        \"visual_style\": \"WIDE_ESTABLISHING_SHOT\",\n",
      "        \"needs_animation\": false,\n",
      "        \"dialogue\": \"We all know the ocean is salty, but why? Why isn't it fresh like the water in rivers and lakes?\",\n",
      "        \"voice_tone\": \"CALM\",\n",
      "        \"transition\": \"FADE\"\n",
      "      },\n",
      "      {\n",
      "        \"scene_type\": \"DEVELOPMENT\",\n",
      "        \"visual_style\": \"DIAGRAM_EXPLANATION\",\n",
      "        \"needs_animation\": true,\n",
      "        \"video_prompt\": \"Dr. Coral points to a diagram showing rain dissolving minerals from rocks.  The animation shows tiny particles breaking away and flowing into streams.  Dr. Coral smiles.\",\n",
      "        \"dialogue\": \"It all starts with rain! As rainwater flows over land, it slowly dissolves minerals from rocks, picking up tiny salt particles.\",\n",
      "        \"voice_tone\": \"FRIENDLY\",\n",
      "        \"transition\": \"SLIDE_RIGHT\"\n",
      "      },\n",
      "      {\n",
      "        \"scene_type\": \"DEVELOPMENT\",\n",
      "        \"visual_style\": \"FOUR_CUT_CARTOON\",\n",
      "        \"needs_animation\": true,\n",
      "        \"video_prompt\": \"Panel 1: Main character pointing at a river. Panel 2: River flowing into the ocean. Panel 3: Salt crystals forming. Panel 4: Main character with a satisfied expression. Speech balloon: 'It's a slow process!'\",\n",
      "        \"dialogue\": \"These minerals, including salt, are carried by rivers and streams into the ocean.  Over millions of years, this process repeats, gradually increasing the ocean's salinity.\",\n",
      "        \"voice_tone\": \"CONFIDENT\",\n",
      "        \"transition\": \"ZOOM_IN\"\n",
      "      },\n",
      "      {\n",
      "        \"scene_type\": \"CLIMAX\",\n",
      "        \"visual_style\": \"CINEMATIC\",\n",
      "        \"needs_animation\": true,\n",
      "        \"video_prompt\": \"Dr. Coral stands dramatically on a beach with a sweeping view of the ocean, a slow zoom in on her face as she reveals the truth. Dramatic music swells.\",\n",
      "        \"dialogue\": \"The key is time!  The ocean's saltiness is the result of billions of years of this continuous process.  It's a truly ancient recipe!\",\n",
      "        \"voice_tone\": \"DRAMATIC\",\n",
      "        \"transition\": \"DISSOLVE\"\n",
      "      },\n",
      "      {\n",
      "        \"scene_type\": \"RESOLUTION\",\n",
      "        \"visual_style\": \"COMPARISON\",\n",
      "        \"needs_animation\": false,\n",
      "        \"dialogue\": \"So, while the ocean is full of salt, it's not something we can easily drink.  The high concentration of salt can actually dehydrate us!\",\n",
      "        \"voice_tone\": \"SERIOUS\",\n",
      "        \"transition\": \"FADE\"\n",
      "      },\n",
      "      {\n",
      "        \"scene_type\": \"CONCLUSION\",\n",
      "        \"visual_style\": \"SPEECH_BUBBLE\",\n",
      "        \"needs_animation\": true,\n",
      "        \"video_prompt\": \"Main character with a thumbs-up and speech balloon saying 'Amazing, right?'\",\n",
      "        \"dialogue\": \"The ocean's saltiness is a testament to the power of time and the constant cycling of water on our planet.  It's a fascinating story!\",\n",
      "        \"voice_tone\": \"ENTHUSIASTIC\",\n",
      "        \"transition\": null\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a simple topic\n",
    "print(\"Testing video script generation...\")\n",
    "result = generate_video_script(\"How Elon must became a CEO of Tesla\", \"English\", 5)\n",
    "print(f\"\\nGenerated Video Script:\\n{result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
